{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055ff931-70bc-49db-8343-41b92f3f104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sgeco\\anaconda3\\envs\\tf\\lib\\site-packages (from opencv-python) (1.24.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.6/39.5 MB 12.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 12.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.3/39.5 MB 9.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 8.9/39.5 MB 10.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.5/39.5 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.2/39.5 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.8/39.5 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.4/39.5 MB 10.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/39.5 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 23.6/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.2/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.8/39.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 31.5/39.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.1/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.7/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 11.4 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python flask Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6198d-af96-4072-a7d8-d44efbf7bbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 모델 로딩 중...\n",
      "✅ 모델 로드 완료!\n",
      "🚀 서버 시작 중...\n",
      "📝 개선된 전처리 알고리즘이 적용되었습니다.\n",
      "🎯 Grad-CAM이 원본 이미지에 오버레이됩니다.\n",
      "⚠️  전처리 실패 시 관리자 알림 기능이 활성화되었습니다.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:8001\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 22:59:37] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 22:59:48] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 22:59:54] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 22:59:59] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:06] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:12] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:18] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:33] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:38] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:00:55] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:01:04] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jun/2025 23:01:10] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "FocusNet-LC 웹 인터페이스 - 폐암 진단 및 Grad-CAM 시각화 (개선된 전처리 통합)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import Flask, request, render_template, jsonify, send_file\n",
    "from werkzeug.utils import secure_filename\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from skimage import morphology, measure, segmentation\n",
    "from lungmask import LMInferer\n",
    "import SimpleITK as sitk\n",
    "\n",
    "h5_path = \"lung_model.h5\"\n",
    "\n",
    "# 설정\n",
    "IMG_SIZE = 512\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size\n",
    "\n",
    "# 업로드 폴더 생성\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "# 클래스 라벨\n",
    "CLASS_NAMES = ['Normal', 'Benign', 'Malignant']\n",
    "CLASS_COLORS = ['#28a745', '#ffc107', '#dc3545']  # 초록, 노랑, 빨강\n",
    "def lung_preprocessing_flask(image_path):\n",
    "    \"\"\"\n",
    "    Flask용 개선된 CT 이미지 폐 전처리 함수\n",
    "    \n",
    "    Args:\n",
    "        image_path: 이미지 경로\n",
    "    \n",
    "    Returns:\n",
    "        lung_mask: 폐 영역 마스크 (0-1)\n",
    "        lung_image: 전처리된 폐 이미지 (0-1)\n",
    "        original_image: 원본 이미지 (0-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 이미지 로드\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    original_normalized = img.astype(np.float32) / 255.0\n",
    "    img_height, img_width = original_normalized.shape\n",
    "    center_x, center_y = img_width // 2, img_height // 2\n",
    "    \n",
    "    # 1. 몸통 추출\n",
    "    img_hu_approx = (original_normalized * 2000) - 1000\n",
    "    body_mask = img_hu_approx > -100\n",
    "    \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    body_mask = cv2.morphologyEx(body_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # 몸통 선택 (중앙에 가장 가까운 큰 영역)\n",
    "    contours, _ = cv2.findContours(body_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        min_body_area = body_mask.size * 0.15\n",
    "        max_body_area = body_mask.size * 0.8\n",
    "        \n",
    "        best_contour = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if min_body_area <= area <= max_body_area:\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    distance = np.sqrt((cx - center_x)**2 + (cy - center_y)**2)\n",
    "                    \n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_contour = contour\n",
    "        \n",
    "        if best_contour is not None:\n",
    "            body_mask = np.zeros_like(body_mask)\n",
    "            cv2.fillPoly(body_mask, [best_contour], 1)\n",
    "        else:\n",
    "            return None, None, None\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    # 2. 베드 영역 제거\n",
    "    bed_mask = np.zeros_like(body_mask, dtype=bool)\n",
    "    \n",
    "    # 하단 15%, 좌우 8% 제거\n",
    "    bottom_region = int(img_height * 0.15)\n",
    "    side_margin = int(img_width * 0.08)\n",
    "    bed_mask[-bottom_region:, :] = True\n",
    "    bed_mask[:, :side_margin] = True\n",
    "    bed_mask[:, -side_margin:] = True\n",
    "    \n",
    "    # 몸통 외부 어두운 영역 제거\n",
    "    expanded_body = cv2.dilate(body_mask, np.ones((15, 15), np.uint8), iterations=2)\n",
    "    outside_body = ~expanded_body.astype(bool)\n",
    "    dark_areas = original_normalized < 0.1\n",
    "    bed_mask = bed_mask | (outside_body & dark_areas)\n",
    "    \n",
    "    # 3. 하얀 조직 및 혈관 제거\n",
    "    enhanced = np.clip(original_normalized * 1.2 + 0.1, 0, 1)\n",
    "    white_mask = (enhanced * body_mask) > 0.75\n",
    "    \n",
    "    # 혈관/염증 영역 제거 (너무 밝은 부분)\n",
    "    vessel_mask = (original_normalized > 0.65) & body_mask.astype(bool)\n",
    "    \n",
    "    # 폐 영역 마스크 생성 (더 엄격한 밝기 범위)\n",
    "    intensity_mask = (original_normalized >= 0.18) & (original_normalized <= 0.5)\n",
    "    lung_mask = body_mask.astype(bool) & ~white_mask & ~bed_mask & ~vessel_mask & intensity_mask\n",
    "    \n",
    "    # 4. 몸통 경계 수축\n",
    "    eroded_body = cv2.erode(body_mask, np.ones((7, 7), np.uint8), iterations=2)\n",
    "    lung_mask = lung_mask & eroded_body.astype(bool)\n",
    "    \n",
    "    # 5. 폐 영역 선택 (좌우 대칭성 고려)\n",
    "    contours, _ = cv2.findContours(lung_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    final_mask = np.zeros_like(lung_mask, dtype=np.uint8)\n",
    "    body_area = np.sum(body_mask)\n",
    "    min_area = body_area * 0.005\n",
    "    max_area = body_area * 0.35\n",
    "    \n",
    "    # 유효한 폐 영역 찾기\n",
    "    valid_regions = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if min_area <= area <= max_area:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                \n",
    "                # 위치 검증\n",
    "                if (cy < img_height * 0.7 and \n",
    "                    img_width * 0.15 < cx < img_width * 0.85):\n",
    "                    center_distance = abs(cx - center_x) / (img_width / 2)\n",
    "                    valid_regions.append((contour, area, cx, cy, center_distance))\n",
    "    \n",
    "    # 좌우 폐 선택\n",
    "    if len(valid_regions) >= 2:\n",
    "        # 면적 순 정렬\n",
    "        valid_regions.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 좌우 분리된 영역 찾기\n",
    "        selected = [valid_regions[0]]  # 가장 큰 영역\n",
    "        \n",
    "        for i in range(1, min(len(valid_regions), 4)):\n",
    "            region1, region2 = selected[0], valid_regions[i]\n",
    "            cx1, cx2 = region1[2], region2[2]\n",
    "            \n",
    "            # 좌우 분리 확인\n",
    "            if abs(cx1 - cx2) > img_width * 0.1:\n",
    "                area_ratio = min(region1[1], region2[1]) / max(region1[1], region2[1])\n",
    "                if area_ratio > 0.15:  # 면적 비율 검증\n",
    "                    selected.append(region2)\n",
    "                    break\n",
    "        \n",
    "        # 좌우 균형 검증\n",
    "        left_count = sum(1 for r in selected if r[2] < center_x)\n",
    "        right_count = sum(1 for r in selected if r[2] > center_x)\n",
    "        \n",
    "        if left_count == 0 or right_count == 0:\n",
    "            # 균형이 안 맞으면 재선택\n",
    "            for i in range(min(len(valid_regions), 3)):\n",
    "                for j in range(i+1, min(len(valid_regions), 4)):\n",
    "                    r1, r2 = valid_regions[i], valid_regions[j]\n",
    "                    if (r1[2] < center_x < r2[2]) or (r2[2] < center_x < r1[2]):\n",
    "                        selected = [r1, r2]\n",
    "                        break\n",
    "                if len(selected) == 2:\n",
    "                    break\n",
    "        \n",
    "        # 선택된 영역 마스크에 추가\n",
    "        for region in selected:\n",
    "            cv2.fillPoly(final_mask, [region[0]], 1)\n",
    "            \n",
    "    elif len(valid_regions) == 1:\n",
    "        cv2.fillPoly(final_mask, [valid_regions[0][0]], 1)\n",
    "    \n",
    "    # 최종 결과\n",
    "    lung_mask_final = final_mask.astype(bool)\n",
    "    lung_image = original_normalized * lung_mask_final\n",
    "    \n",
    "    return lung_mask_final, lung_image, original_normalized\n",
    "\n",
    "\n",
    "def preprocess_image_with_improved_segmentation(image_path):\n",
    "    \"\"\"\n",
    "    개선된 이미지 전처리 함수 (Flask 인터페이스와 호환)\n",
    "    \n",
    "    Args:\n",
    "        image_path: 이미지 파일 경로\n",
    "        \n",
    "    Returns:\n",
    "        processed_img: 전처리된 이미지 (512x512, 0-1 범위)\n",
    "        original_img: 원본 이미지 (512x512, 0-1 범위)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 개선된 폐 전처리 적용\n",
    "        lung_mask, lung_img, original_img = lung_preprocessing_flask(image_path)\n",
    "        \n",
    "        if lung_mask is None:\n",
    "            return None, None\n",
    "        \n",
    "        # 폐 비율 검증\n",
    "        lung_ratio = np.sum(lung_mask) / lung_mask.size\n",
    "        if not (0.003 < lung_ratio < 0.45):\n",
    "            print(f\"폐 비율 검증 실패: {lung_ratio:.3f}\")\n",
    "            return None, None\n",
    "        \n",
    "        # 512x512로 리사이즈\n",
    "        processed_img = cv2.resize(lung_img, (512, 512))\n",
    "        original_resized = cv2.resize(original_img, (512, 512))\n",
    "        \n",
    "        # 정규화 (0-1 범위)\n",
    "        processed_img = processed_img.astype(np.float32)\n",
    "        original_resized = original_resized.astype(np.float32)\n",
    "        \n",
    "        return processed_img, original_resized\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"전처리 오류: {e}\")\n",
    "        return None, None\n",
    "def allowed_file(filename):\n",
    "    \"\"\"허용된 파일 확장자 확인\"\"\"\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def build_focusnetlc(input_shape=(IMG_SIZE, IMG_SIZE, 1), meta_dim=2):\n",
    "    \"\"\"FocusNet-LC 모델 구조 정의 (학습 시와 동일)\"\"\"\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(img_input)\n",
    "    x = Conv2D(64, (3, 3),strides=2, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(1024, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(1024, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    meta_input = Input(shape=(meta_dim,))\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=[img_input, meta_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    \"\"\"Grad-CAM 히트맵 생성\"\"\"\n",
    "    preds = model.predict(img_array)\n",
    "    pred_index = tf.argmax(preds[0])\n",
    "    \n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, pred_index]\n",
    "    \n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def create_gradcam_image(original_img, heatmap, alpha=0.6):\n",
    "    \"\"\"Grad-CAM 오버레이 이미지 생성 (원본 이미지에 히트맵 오버레이)\"\"\"\n",
    "    # 히트맵을 원본 이미지 크기에 맞게 리사이즈\n",
    "    heatmap_resized = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # 히트맵을 컬러맵으로 변환 (jet 컬러맵 사용)\n",
    "    heatmap_colored = plt.cm.jet(heatmap_resized)[..., :3]\n",
    "    \n",
    "    # 원본 이미지를 3채널로 변환 (그레이스케일을 RGB로)\n",
    "    if len(original_img.shape) == 2:\n",
    "        original_img_3ch = np.stack([original_img]*3, axis=-1)\n",
    "    else:\n",
    "        original_img_3ch = original_img\n",
    "    \n",
    "    # 원본 이미지 정규화 (0-1 범위로)\n",
    "    original_img_normalized = original_img_3ch / np.max(original_img_3ch) if np.max(original_img_3ch) > 0 else original_img_3ch\n",
    "    \n",
    "    # 히트맵에서 투명도 마스크 생성 (히트맵 값이 낮은 곳은 투명하게)\n",
    "    transparency_mask = heatmap_resized\n",
    "    transparency_mask = np.stack([transparency_mask]*3, axis=-1)\n",
    "    \n",
    "    # 알파 블렌딩: 히트맵 강도에 따라 투명도 조절\n",
    "    # 히트맵이 강한 곳은 더 불투명하게, 약한 곳은 더 투명하게\n",
    "    dynamic_alpha = alpha * transparency_mask\n",
    "    \n",
    "    # 최종 이미지 합성\n",
    "    superimposed_img = (heatmap_colored * dynamic_alpha + \n",
    "                       original_img_normalized * (1 - dynamic_alpha))\n",
    "    \n",
    "    # 0-255 범위로 변환\n",
    "    superimposed_img = np.uint8(255 * superimposed_img)\n",
    "    \n",
    "    return superimposed_img\n",
    "\n",
    "# 모델 로드\n",
    "print(\"🔄 모델 로딩 중...\")\n",
    "try:\n",
    "    # 먼저 모델 구조 생성\n",
    "    model = build_focusnetlc()\n",
    "    # 가중치 로드\n",
    "    model.load_weights(h5_path)\n",
    "    \n",
    "    print(\"✅ 모델 로드 완료!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 모델 로드 실패: {e}\")\n",
    "    model = None\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"메인 페이지\"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"이미지 예측 및 Grad-CAM 생성\"\"\"\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': '파일이 선택되지 않았습니다.'})\n",
    "    \n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': '파일이 선택되지 않았습니다.'})\n",
    "    \n",
    "    if file and allowed_file(file.filename):\n",
    "        try:\n",
    "            # 파일 저장\n",
    "            filename = secure_filename(file.filename)\n",
    "            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "            file.save(filepath)\n",
    "            \n",
    "            # 개선된 이미지 전처리 (원본 이미지도 함께 반환)\n",
    "            processed_img, original_img = preprocess_image_with_improved_segmentation(filepath)\n",
    "            if processed_img is None:\n",
    "                # 전처리 실패 시 관리자에게 알림 메시지\n",
    "                return jsonify({\n",
    "                    'error': '전처리 실패',\n",
    "                    'message': '이 CT 이미지는 자동 분석이 어려워 관리자에게 전송되었습니다. 수동 검토 후 결과를 알려드리겠습니다.',\n",
    "                    'admin_notification': True\n",
    "                })\n",
    "            \n",
    "            # 모델 입력 형태로 변환\n",
    "            img_array = processed_img.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
    "            meta_array = np.array([[0.1, 0.1]])  # 더미 메타데이터\n",
    "            \n",
    "            # 예측\n",
    "            predictions = model.predict([img_array, meta_array])\n",
    "            pred_class = np.argmax(predictions[0])\n",
    "            confidence = float(predictions[0][pred_class])\n",
    "            \n",
    "            # Grad-CAM 생성\n",
    "            count =0\n",
    "            last_conv_layer = None\n",
    "            for layer in reversed(model.layers):\n",
    "                if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                    count = count +1\n",
    "                    if(count >= 5) : \n",
    "                        last_conv_layer = layer.name\n",
    "                        break\n",
    "            \n",
    "            if last_conv_layer:\n",
    "                heatmap = make_gradcam_heatmap([img_array, meta_array], model, last_conv_layer)\n",
    "                # 원본 이미지에 Grad-CAM 오버레이\n",
    "                gradcam_img = create_gradcam_image(original_img, heatmap)\n",
    "                \n",
    "                # 이미지를 base64로 인코딩\n",
    "                _, buffer = cv2.imencode('.png', gradcam_img)\n",
    "                gradcam_b64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            else:\n",
    "                gradcam_b64 = None\n",
    "            \n",
    "            # 원본 이미지도 base64로 인코딩\n",
    "            _, orig_buffer = cv2.imencode('.png', original_img * 255)\n",
    "            original_b64 = base64.b64encode(orig_buffer).decode('utf-8')\n",
    "            \n",
    "            # 전처리된 이미지도 base64로 인코딩\n",
    "            _, proc_buffer = cv2.imencode('.png', processed_img * 255)\n",
    "            processed_b64 = base64.b64encode(proc_buffer).decode('utf-8')\n",
    "            \n",
    "            # 결과 반환\n",
    "            result = {\n",
    "                'prediction': CLASS_NAMES[pred_class],\n",
    "                'confidence': round(confidence * 100, 2),\n",
    "                'color': CLASS_COLORS[pred_class],\n",
    "                'all_predictions': {\n",
    "                    CLASS_NAMES[i]: round(float(predictions[0][i]) * 100, 2) \n",
    "                    for i in range(len(CLASS_NAMES))\n",
    "                },\n",
    "                'original_image': f\"data:image/png;base64,{original_b64}\",\n",
    "                'processed_image': f\"data:image/png;base64,{processed_b64}\",\n",
    "                'gradcam_image': f\"data:image/png;base64,{gradcam_b64}\" if gradcam_b64 else None,\n",
    "                'preprocessing_success': True\n",
    "            }\n",
    "            \n",
    "            # 임시 파일 삭제\n",
    "            os.remove(filepath)\n",
    "            \n",
    "            return jsonify(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 임시 파일 삭제 (실패 시에도)\n",
    "            if 'filepath' in locals() and os.path.exists(filepath):\n",
    "                os.remove(filepath)\n",
    "            \n",
    "            return jsonify({\n",
    "                'error': '처리 중 오류 발생',\n",
    "                'message': f'시스템 오류가 발생했습니다: {str(e)}',\n",
    "                'admin_notification': True\n",
    "            })\n",
    "    \n",
    "    return jsonify({'error': '잘못된 파일 형식입니다.'})\n",
    "\n",
    "# HTML 템플릿 (수정된 버전)\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ko\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>FocusNet-LC 폐암 진단</title>\n",
    "    <style>\n",
    "        * {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            box-sizing: border-box;\n",
    "        }\n",
    "        \n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            min-height: 100vh;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        \n",
    "        .container {\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            background: white;\n",
    "            border-radius: 20px;\n",
    "            box-shadow: 0 20px 40px rgba(0,0,0,0.1);\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        \n",
    "        .header {\n",
    "            background: linear-gradient(135deg, #2c3e50, #3498db);\n",
    "            color: white;\n",
    "            padding: 30px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .header h1 {\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        \n",
    "        .header p {\n",
    "            font-size: 1.2em;\n",
    "            opacity: 0.9;\n",
    "        }\n",
    "        \n",
    "        .content {\n",
    "            padding: 40px;\n",
    "        }\n",
    "        \n",
    "        .upload-section {\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "        }\n",
    "        \n",
    "        .file-input-wrapper {\n",
    "            position: relative;\n",
    "            display: inline-block;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        \n",
    "        .file-input {\n",
    "            display: none;\n",
    "        }\n",
    "        \n",
    "        .file-input-button {\n",
    "            background: linear-gradient(135deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            padding: 15px 30px;\n",
    "            border: none;\n",
    "            border-radius: 50px;\n",
    "            font-size: 1.1em;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s;\n",
    "        }\n",
    "        \n",
    "        .file-input-button:hover {\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 10px 20px rgba(0,0,0,0.2);\n",
    "        }\n",
    "        \n",
    "        .predict-button {\n",
    "            background: linear-gradient(135deg, #28a745, #20c997);\n",
    "            color: white;\n",
    "            padding: 15px 40px;\n",
    "            border: none;\n",
    "            border-radius: 50px;\n",
    "            font-size: 1.2em;\n",
    "            cursor: pointer;\n",
    "            margin-left: 20px;\n",
    "            transition: all 0.3s;\n",
    "        }\n",
    "        \n",
    "        .predict-button:hover {\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 10px 20px rgba(0,0,0,0.2);\n",
    "        }\n",
    "        \n",
    "        .predict-button:disabled {\n",
    "            background: #ccc;\n",
    "            cursor: not-allowed;\n",
    "            transform: none;\n",
    "            box-shadow: none;\n",
    "        }\n",
    "        \n",
    "        .results-section {\n",
    "            display: none;\n",
    "            margin-top: 40px;\n",
    "        }\n",
    "        \n",
    "        .prediction-card {\n",
    "            background: #f8f9fa;\n",
    "            border-radius: 15px;\n",
    "            padding: 30px;\n",
    "            margin-bottom: 30px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .prediction-result {\n",
    "            font-size: 2em;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        \n",
    "        .confidence {\n",
    "            font-size: 1.5em;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        \n",
    "        .all-predictions {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 15px;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        \n",
    "        .prediction-item {\n",
    "            background: white;\n",
    "            padding: 15px;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 5px 15px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        \n",
    "        .images-container {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));\n",
    "            gap: 30px;\n",
    "            margin-top: 30px;\n",
    "        }\n",
    "        \n",
    "        .image-card {\n",
    "            background: #f8f9fa;\n",
    "            border-radius: 15px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .image-card h3 {\n",
    "            margin-bottom: 15px;\n",
    "            color: #333;\n",
    "        }\n",
    "        \n",
    "        .image-card img {\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 10px 20px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        \n",
    "        .loading {\n",
    "            display: none;\n",
    "            text-align: center;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        \n",
    "        .spinner {\n",
    "            border: 4px solid #f3f3f3;\n",
    "            border-top: 4px solid #3498db;\n",
    "            border-radius: 50%;\n",
    "            width: 50px;\n",
    "            height: 50px;\n",
    "            animation: spin 1s linear infinite;\n",
    "            margin: 0 auto 20px;\n",
    "        }\n",
    "        \n",
    "        @keyframes spin {\n",
    "            0% { transform: rotate(0deg); }\n",
    "            100% { transform: rotate(360deg); }\n",
    "        }\n",
    "        \n",
    "        .error-message {\n",
    "            background: #dc3545;\n",
    "            color: white;\n",
    "            padding: 15px;\n",
    "            border-radius: 10px;\n",
    "            margin: 20px 0;\n",
    "            display: none;\n",
    "        }\n",
    "        \n",
    "        .admin-message {\n",
    "            background: #ffc107;\n",
    "            color: #856404;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            margin: 20px 0;\n",
    "            display: none;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .admin-message h4 {\n",
    "            margin-bottom: 10px;\n",
    "            color: #856404;\n",
    "        }\n",
    "        \n",
    "        @media (max-width: 768px) {\n",
    "            .images-container {\n",
    "                grid-template-columns: 1fr;\n",
    "            }\n",
    "            \n",
    "            .predict-button {\n",
    "                margin-left: 0;\n",
    "                margin-top: 10px;\n",
    "            }\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>AI Bread Scan</h1>\n",
    "            <p>AI 기반 폐암 진단 시스템 (서강대 AISW 텐서플로 활용기초)</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"content\">\n",
    "            <div class=\"upload-section\">\n",
    "                <h2>CT 이미지를 업로드하세요</h2>\n",
    "                <div class=\"file-input-wrapper\">\n",
    "                    <input type=\"file\" id=\"fileInput\" class=\"file-input\" accept=\".png,.jpg,.jpeg\">\n",
    "                    <button class=\"file-input-button\" onclick=\"document.getElementById('fileInput').click()\">\n",
    "                        📁 파일 선택\n",
    "                    </button>\n",
    "                </div>\n",
    "                <button class=\"predict-button\" id=\"predictButton\" disabled onclick=\"predict()\">\n",
    "                    🔍 진단 시작\n",
    "                </button>\n",
    "                <div id=\"fileName\" style=\"margin-top: 10px; color: #666;\"></div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"loading\" id=\"loading\">\n",
    "                <div class=\"spinner\"></div>\n",
    "                <p>AI가 이미지를 분석하고 있습니다...</p>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"error-message\" id=\"errorMessage\"></div>\n",
    "            \n",
    "            <div class=\"admin-message\" id=\"adminMessage\">\n",
    "                <h4>⚠️ 전처리 실패</h4>\n",
    "                <p id=\"adminMessageText\"></p>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"results-section\" id=\"resultsSection\">\n",
    "                <div class=\"prediction-card\">\n",
    "                    <div class=\"prediction-result\" id=\"predictionResult\"></div>\n",
    "                    <div class=\"confidence\" id=\"confidence\"></div>\n",
    "                    <div class=\"all-predictions\" id=\"allPredictions\"></div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"images-container\">\n",
    "                    <div class=\"image-card\">\n",
    "                        <h3>📷 원본 이미지</h3>\n",
    "                        <img id=\"originalImage\" src=\"\" alt=\"원본 이미지\">\n",
    "                    </div>\n",
    "                    <div class=\"image-card\">\n",
    "                        <h3>🔍 전처리된 이미지</h3>\n",
    "                        <img id=\"processedImage\" src=\"\" alt=\"전처리된 이미지\">\n",
    "                    </div>\n",
    "                    <div class=\"image-card\">\n",
    "                        <h3>🎯 Grad-CAM 히트맵</h3>\n",
    "                        <img id=\"gradcamImage\" src=\"\" alt=\"Grad-CAM 히트맵\">\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        document.getElementById('fileInput').addEventListener('change', function(e) {\n",
    "            const file = e.target.files[0];\n",
    "            const predictButton = document.getElementById('predictButton');\n",
    "            const fileName = document.getElementById('fileName');\n",
    "            \n",
    "            if (file) {\n",
    "                fileName.textContent = `선택된 파일: ${file.name}`;\n",
    "                predictButton.disabled = false;\n",
    "            } else {\n",
    "                fileName.textContent = '';\n",
    "                predictButton.disabled = true;\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        function showError(message) {\n",
    "            const errorDiv = document.getElementById('errorMessage');\n",
    "            errorDiv.textContent = message;\n",
    "            errorDiv.style.display = 'block';\n",
    "            setTimeout(() => {\n",
    "                errorDiv.style.display = 'none';\n",
    "            }, 10000);\n",
    "        }\n",
    "        \n",
    "        function showAdminMessage(message) {\n",
    "            const adminDiv = document.getElementById('adminMessage');\n",
    "            const adminText = document.getElementById('adminMessageText');\n",
    "            adminText.textContent = message;\n",
    "            adminDiv.style.display = 'block';\n",
    "            \n",
    "            // 10초 후 자동으로 숨김\n",
    "            setTimeout(() => {\n",
    "                adminDiv.style.display = 'none';\n",
    "            }, 15000);\n",
    "        }\n",
    "        \n",
    "        async function predict() {\n",
    "            const fileInput = document.getElementById('fileInput');\n",
    "            const file = fileInput.files[0];\n",
    "            \n",
    "            if (!file) {\n",
    "                showError('파일을 선택해주세요.');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            // UI 상태 변경\n",
    "            document.getElementById('loading').style.display = 'block';\n",
    "            document.getElementById('resultsSection').style.display = 'none';\n",
    "            document.getElementById('errorMessage').style.display = 'none';\n",
    "            document.getElementById('adminMessage').style.display = 'none';\n",
    "            document.getElementById('predictButton').disabled = true;\n",
    "            \n",
    "            const formData = new FormData();\n",
    "            formData.append('file', file);\n",
    "            \n",
    "            try {\n",
    "                const response = await fetch('/predict', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "                \n",
    "                const result = await response.json();\n",
    "                \n",
    "                if (result.error) {\n",
    "                    if (result.admin_notification) {\n",
    "                        // 관리자 알림 메시지 표시\n",
    "                        showAdminMessage(result.message || result.error);\n",
    "                    } else {\n",
    "                        // 일반 오류 메시지 표시\n",
    "                        showError(result.error);\n",
    "                    }\n",
    "                    return;\n",
    "                }\n",
    "                \n",
    "                // 결과 표시\n",
    "                document.getElementById('predictionResult').textContent = result.prediction;\n",
    "                document.getElementById('predictionResult').style.color = result.color;\n",
    "                document.getElementById('confidence').textContent = `신뢰도: ${result.confidence}%`;\n",
    "                \n",
    "                // 모든 예측 결과 표시\n",
    "                const allPredDiv = document.getElementById('allPredictions');\n",
    "                allPredDiv.innerHTML = '';\n",
    "                for (const [className, confidence] of Object.entries(result.all_predictions)) {\n",
    "                    const div = document.createElement('div');\n",
    "                    div.className = 'prediction-item';\n",
    "                    div.innerHTML = `<strong>${className}</strong><br>${confidence}%`;\n",
    "                    allPredDiv.appendChild(div);\n",
    "                }\n",
    "                \n",
    "                // 이미지 표시\n",
    "                document.getElementById('originalImage').src = result.original_image;\n",
    "                document.getElementById('processedImage').src = result.processed_image;\n",
    "                if (result.gradcam_image) {\n",
    "                    document.getElementById('gradcamImage').src = result.gradcam_image;\n",
    "                }\n",
    "                \n",
    "                document.getElementById('resultsSection').style.display = 'block';\n",
    "                \n",
    "            } catch (error) {\n",
    "                showError('서버 연결 오류가 발생했습니다.');\n",
    "                console.error('Error:', error);\n",
    "            } finally {\n",
    "                document.getElementById('loading').style.display = 'none';\n",
    "                document.getElementById('predictButton').disabled = false;\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# 템플릿 폴더 생성 및 HTML 파일 저장\n",
    "template_dir = 'templates'\n",
    "os.makedirs(template_dir, exist_ok=True)\n",
    "with open(os.path.join(template_dir, 'index.html'), 'w', encoding='utf-8') as f:\n",
    "    f.write(HTML_TEMPLATE)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if model is None:\n",
    "        print(\"❌ 모델을 로드할 수 없어 서버를 시작할 수 없습니다.\")\n",
    "    else:\n",
    "        print(\"🚀 서버 시작 중...\")\n",
    "        print(\"📝 개선된 전처리 알고리즘이 적용되었습니다.\")\n",
    "        print(\"🎯 Grad-CAM이 원본 이미지에 오버레이됩니다.\")\n",
    "        print(\"⚠️  전처리 실패 시 관리자 알림 기능이 활성화되었습니다.\")\n",
    "        # 실제 배포 시에는 host를 '0.0.0.0'으로 설정\n",
    "        app.run(host='localhost', port=8001, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d996985-491b-4191-a5b6-298a1684b448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ed1d6-cbea-436f-b856-d180568558aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
